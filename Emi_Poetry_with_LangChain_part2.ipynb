{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sdossou/Emi_Poetry/blob/main/Emi_Poetry_with_LangChain_part2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Emily Dickinson Focused Chatbot\n",
        "\n",
        "#### This model is generating research holistically about Emily Dickinson's life, poetry and legacy"
      ],
      "metadata": {
        "id": "xhv1s2p7aTdd"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install all relevant dependencies"
      ],
      "metadata": {
        "id": "2BeYvqcZbfjM"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fXsYHTgvnCM2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "06b1a934-920a-4931-b619-f9f60faf4d12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.4/262.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m810.5/810.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m13.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m269.1/269.1 kB\u001b[0m \u001b[31m14.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.6/71.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.8/77.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.5/138.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install openai langchain -q"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U langchain-community"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oqkhc8XygVD8",
        "outputId": "91350dcf-eba1-4216-9c12-7869c52ad4cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain-community in /usr/local/lib/python3.10/dist-packages (0.0.29)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (3.9.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.6.4)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (0.1.31)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (1.25.2)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-community) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.9.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (4.0.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (3.7.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.33->langchain-community) (2.6.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-community) (3.9.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain-community) (2024.2.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (4.10.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain-community) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-community) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.33->langchain-community) (1.2.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.33->langchain-community) (2.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-community) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.2.0,>=0.1.33->langchain-community) (2.16.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Loading Emily Dickinson Source Document\n",
        "\n",
        "Selection of Emily Dickinson's complete works divided into four text files and a website page on her work.\n",
        "\n",
        "The datasets have been saved on the huggingface plateform."
      ],
      "metadata": {
        "id": "Kc4kbWNubq-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/financeart/EmiTalks1/blob/main/EmilyDickinsonCompleteWorks3.txt-O \"EmiTalks_1.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0xbniGJzcsgK",
        "outputId": "de3d2abf-b43d-4f78-a8ef-a6148d7973ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 16:59:23--  https://huggingface.co/datasets/financeart/EmiTalks1/blob/main/EmilyDickinsonCompleteWorks3.txt-O\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.74, 3.163.189.37, 3.163.189.90, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 404 Not Found\n",
            "2024-03-24 16:59:24 ERROR 404: Not Found.\n",
            "\n",
            "--2024-03-24 16:59:24--  http://emitalks_1.txt/\n",
            "Resolving emitalks_1.txt (emitalks_1.txt)... failed: Name or service not known.\n",
            "wget: unable to resolve host address ‘emitalks_1.txt’\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/financeart/EmiTalks2/blob/main/EmilyDickinsonCompleteWorks2.txt -O \"EmiTalks_2.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nKtQ4IHokzq6",
        "outputId": "36f6f8d5-6eee-4f77-b7ba-b79711a17077"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 16:59:32--  https://huggingface.co/datasets/financeart/EmiTalks2/blob/main/EmilyDickinsonCompleteWorks2.txt\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.74, 3.163.189.37, 3.163.189.90, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.74|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 271158 (265K) [text/html]\n",
            "Saving to: ‘EmiTalks_2.htm’\n",
            "\n",
            "\rEmiTalks_2.htm        0%[                    ]       0  --.-KB/s               \rEmiTalks_2.htm      100%[===================>] 264.80K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-03-24 16:59:33 (7.81 MB/s) - ‘EmiTalks_2.htm’ saved [271158/271158]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/financeart/EmiTalks3/blob/main/EmilyDickinsonCompleteWorks1.txt -O \"EmiTalks_3.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oGsJT4a1lXHn",
        "outputId": "68fada37-7c70-43c6-e86d-dcdc87c8a904"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 16:59:37--  https://huggingface.co/datasets/financeart/EmiTalks3/blob/main/EmilyDickinsonCompleteWorks1.txt\n",
            "Resolving huggingface.co (huggingface.co)... 99.84.66.65, 99.84.66.70, 99.84.66.72, ...\n",
            "Connecting to huggingface.co (huggingface.co)|99.84.66.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 231836 (226K) [text/html]\n",
            "Saving to: ‘EmiTalks_3.txt’\n",
            "\n",
            "EmiTalks_3.txt      100%[===================>] 226.40K  --.-KB/s    in 0.03s   \n",
            "\n",
            "2024-03-24 16:59:38 (7.34 MB/s) - ‘EmiTalks_3.txt’ saved [231836/231836]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://huggingface.co/datasets/financeart/EmiTalks4/blob/main/Emily%20Dickinson%204.txt -O \"EmiTalks_4.txt\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jo2OtO4Bll52",
        "outputId": "fed9b8db-11a6-4911-95df-85e5e44c1eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-24 16:59:44--  https://huggingface.co/datasets/financeart/EmiTalks4/blob/main/Emily%20Dickinson%204.txt\n",
            "Resolving huggingface.co (huggingface.co)... 3.163.189.90, 3.163.189.37, 3.163.189.114, ...\n",
            "Connecting to huggingface.co (huggingface.co)|3.163.189.90|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 226437 (221K) [text/html]\n",
            "Saving to: ‘EmiTalks_4.htm’\n",
            "\n",
            "\rEmiTalks_4.htm        0%[                    ]       0  --.-KB/s               \rEmiTalks_4.htm      100%[===================>] 221.13K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2024-03-24 16:59:44 (12.0 MB/s) - ‘EmiTalks_4.htm’ saved [226437/226437]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://www.poetryfoundation.org/poets/emily-dickinson -O \"EmiTalks_5.htm\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGogIALaeLzV",
        "outputId": "c27787f6-57f2-4027-9a39-66b9e787646f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-03-25 07:18:18--  https://www.poetryfoundation.org/poets/emily-dickinson\n",
            "Resolving www.poetryfoundation.org (www.poetryfoundation.org)... 104.22.2.86, 104.22.3.86, 172.67.7.91, ...\n",
            "Connecting to www.poetryfoundation.org (www.poetryfoundation.org)|104.22.2.86|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "Saving to: ‘EmiTalks_5.htm’\n",
            "\n",
            "\rEmiTalks_5.htm          [<=>                 ]       0  --.-KB/s               \rEmiTalks_5.htm          [ <=>                ] 404.63K  --.-KB/s    in 0.007s  \n",
            "\n",
            "2024-03-25 07:18:19 (53.0 MB/s) - ‘EmiTalks_5.htm’ saved [414346]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Put the files with various file extensions into a new directory."
      ],
      "metadata": {
        "id": "P_dz_6t2eUD0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from glob import glob\n",
        "\n",
        "files = glob(\"*\")"
      ],
      "metadata": {
        "id": "Vt0Q7LUjeTl4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import shutil\n",
        "import os\n",
        "\n",
        "os.mkdir('./data')\n",
        "\n",
        "for individual_file in files:\n",
        "  if individual_file.find(\".\") == -1:\n",
        "    continue\n",
        "  file_extension = individual_file.split(\".\")[-1]\n",
        "  if not os.path.exists(\"./data/\" + file_extension):\n",
        "    os.mkdir(\"./data/\" + file_extension)\n",
        "  shutil.move(individual_file, \"./data/\" + file_extension)"
      ],
      "metadata": {
        "id": "jvop8FqCe62M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading `.htm ` document with `DirectoryLoader` and `BSHTMLLoader` from BeautifulSoup4 adding some extra metadata.\n",
        "\n"
      ],
      "metadata": {
        "id": "cCtyAm9Zc69y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install dependencies\n",
        "!pip install beautifulsoup4 -q"
      ],
      "metadata": {
        "id": "vmDHzRMBc6GE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain.document_loaders import BSHTMLLoader, DirectoryLoader\n",
        "from langchain_community.document_loaders import BSHTMLLoader, DirectoryLoader\n",
        "\n",
        "bshtml_dir_loader = DirectoryLoader('./data/htm', loader_cls=BSHTMLLoader)\n",
        "\n",
        "data = bshtml_dir_loader.load()"
      ],
      "metadata": {
        "id": "Z5tOC-EceLGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Splitting the document into chunks for the vector database"
      ],
      "metadata": {
        "id": "ChpY604tgqAW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size = 1000,\n",
        "    chunk_overlap  = 20,\n",
        "    length_function = len,\n",
        ")\n",
        "\n",
        "documents = text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "YsNOWcgPij7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Set-up OpenAI API key.\n",
        "\n",
        "Creating embeddings using OpenAIEmbeddings."
      ],
      "metadata": {
        "id": "VZxrOv-Ljmct"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "\n",
        "openai.api_key = userdata.get('openai_key')\n",
        "os.environ[\"OPENAI_API_KEY\"] = openai.api_key"
      ],
      "metadata": {
        "id": "TLjq79dl8ayk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.embeddings.openai import OpenAIEmbeddings\n",
        "\n",
        "embeddings = OpenAIEmbeddings()"
      ],
      "metadata": {
        "id": "AYP_Xlqxi0XT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "37f99210-2b14-4642-cef3-f64f2685d2b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.0.9 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Embedding the chunked documents into a ChromaVectorDB.\n",
        "\n",
        "Creating a persisted version of the VectorDB for showcasing, however not used.\n"
      ],
      "metadata": {
        "id": "3Gg6snZukPLr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# installing chromadb and tiktoken dependencies\n",
        "!pip install chromadb tiktoken -q"
      ],
      "metadata": {
        "id": "_j1gLWEmkVfB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d44a92b5-28e1-44fb-d72a-c65b5f163a99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m525.5/525.5 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m30.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m92.1/92.1 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.3/41.3 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.4/5.4 MB\u001b[0m \u001b[31m50.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.4/58.4 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m105.7/105.7 kB\u001b[0m \u001b[31m15.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m698.9/698.9 kB\u001b[0m \u001b[31m54.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m68.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.8/50.8 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.4/341.4 kB\u001b[0m \u001b[31m38.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m80.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#from langchain.vectorstores import Chroma\n",
        "from langchain_community.vectorstores import Chroma\n",
        "\n",
        "persist_directory = \"vector_db\"\n",
        "\n",
        "vectordb = Chroma.from_documents(documents=documents, embedding=embeddings, persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "nEwp4mDQkZ2i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Persisting Chroma vector store and showcasing how it would be loaded."
      ],
      "metadata": {
        "id": "VfVuNq5flJAs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.persist()\n",
        "vectordb = None"
      ],
      "metadata": {
        "id": "wZ9SuruglF9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading the persisted vectore store is faster than reinstantiating it.\n",
        "\n",
        "This is the benefit of `persist_directory`."
      ],
      "metadata": {
        "id": "isOhiDm6lwoh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma(persist_directory=persist_directory, embedding_function=embeddings)"
      ],
      "metadata": {
        "id": "HBSepKChlfpw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Loading `.txt` documents."
      ],
      "metadata": {
        "id": "51pcelS-m6Ga"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import TextLoader, DirectoryLoader\n",
        "\n",
        "txt_dir_loader = DirectoryLoader('./data/txt', loader_cls=TextLoader)\n",
        "\n",
        "txt_data = txt_dir_loader.load()"
      ],
      "metadata": {
        "id": "7acIb7YEq3mA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Splitting the documents using `RecursiveCharacterSplitter`."
      ],
      "metadata": {
        "id": "FgOstYfWrITX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "txt_documents = text_splitter.split_documents(txt_data)"
      ],
      "metadata": {
        "id": "vWGxR834rALg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "Adding text documents to Chroma Vector database and testing that they have been successfully added."
      ],
      "metadata": {
        "id": "aspB5OGkrQiL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb = Chroma.from_documents(documents=txt_documents, embedding=embeddings, persist_directory=persist_directory)"
      ],
      "metadata": {
        "id": "c7l3ySoJqI9H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectordb.similarity_search(\"shipwreck\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R12ZaBo1reD0",
        "outputId": "6d8d5cc9-13fa-4544-dca7-d92f5fd7a91e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[Document(page_content=\"Earth would have been too much, I see,\\n\\n\\nAnd heaven not enough for me;\\n\\n\\n   I should have had the joy\\n\\n\\nWithout the fear to justify, --\\n\\n\\nThe palm without the Calvary;\\n\\n\\n   So, Saviour, crucify.\\n\\n\\n\\n\\n\\n\\nDefeat whets victory, they say;\\n\\n\\nThe reefs in old Gethsemane\\n\\n\\n   Endear the shore beyond.\\n\\n\\n'T is beggars banquets best define;\\n\\n\\n'T is thirsting vitalizes wine, --\\n\\n\\n   Faith faints to understand.\\n\\n\\n\\n\\n\\n\\nXXV.\\n\\n\\n\\n\\n\\n\\nSHIPWRECK.\\n\\n\\n\\n\\n\\n\\nIt tossed and tossed, --\\n\\n\\nA little brig I knew, --\\n\\n\\nO'ertook by blast,\\n\\n\\nIt spun and spun,\\n\\n\\nAnd groped delirious, for morn.\\n\\n\\n\\n\\n\\n\\nIt slipped and slipped,\\n\\n\\nAs one that drunken stepped;\\n\\n\\nIts white foot tripped,\\n\\n\\nThen dropped from sight.\\n\\n\\n\\n\\n\\n\\nAh, brig, good-night\\n\\n\\nTo crew and you;\\n\\n\\nThe ocean's heart too smooth, too blue,\\n\\n\\nTo break for you.\\n\\n\\n\\n\\n\\n\\nXXVI.\\n\\n\\n\\n\\n\\n\\nVictory comes late,\\n\\n\\nAnd is held low to freezing lips\\n\\n\\nToo rapt with frost\\n\\n\\nTo take it.\\n\\n\\nHow sweet it would have tasted,\\n\\n\\nJust a drop!\\n\\n\\nWas God so economical?\", metadata={'source': 'data/htm/EmiTalks_4.htm', 'title': 'Emily Dickinson 4.txt · financeart/EmiTalks4 at main'}),\n",
              " Document(page_content='I can wade grief,\\n\\n\\nWhole pools of it, --\\n\\n\\nI \\'m used to that.\\n\\n\\nBut the least push of joy\\n\\n\\nBreaks up my feet,\\n\\n\\nAnd I tip -- drunken.\\n\\n\\nLet no pebble smile,\\n\\n\\n\\'T was the new liquor, --\\n\\n\\nThat was all!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nPower is only pain,\\n\\n\\nStranded, through discipline,\\n\\n\\nTill weights will hang.\\n\\n\\nGive balm to giants,\\n\\n\\nAnd they \\'ll wilt, like men.\\n\\n\\nGive Himmaleh, --\\n\\n\\nThey \\'ll carry him!\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nX.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nESCAPE.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nI never hear the word \"escape\"\\n\\n\\nWithout a quicker blood,\\n\\n\\nA sudden expectation,\\n\\n\\nA flying attitude.\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n\\nI never hear of prisons broad\\n\\n\\nBy soldiers battered down,\\n\\n\\nBut I tug childish at my bars, --\\n\\n\\nOnly to fail again!', metadata={'source': 'data/htm/EmiTalks_2.htm', 'title': 'EmilyDickinsonCompleteWorks2.txt · financeart/EmiTalks2 at main'}),\n",
              " Document(page_content='summer could for them;&quot;,&quot;&quot;,&quot;Or Arctic creature, dimly stirred&quot;,&quot;By tropic hint, -- some travelled bird&quot;,&quot;Imported to the wood;&quot;,&quot;&quot;,&quot;Or wind&amp;#x27;s bright signal to the ear,&quot;,&quot;Making that homely and severe,&quot;,&quot;Contented, known, before&quot;,&quot;&quot;,&quot;The heaven unexpected came,&quot;,&quot;To lives that thought their worshipping&quot;,&quot;A too presumptuous psalm.&quot;,&quot;&quot;,&quot;XIII.&quot;,&quot;&quot;,&quot;THE SEA OF SUNSET.&quot;,&quot;&quot;,&quot;This is the land the sunset washes,&quot;,&quot;These are the banks of the Yellow Sea;&quot;,&quot;Where it rose, or whither it rushes,&quot;,&quot;These are the western mystery!&quot;,&quot;&quot;,&quot;Night after night her purple traffic&quot;,&quot;Strews the landing with opal bales;&quot;,&quot;Merchantmen poise upon horizons,&quot;,&quot;Dip, and vanish with fairy', metadata={'source': 'data/txt/EmiTalks_3.txt'}),\n",
              " Document(page_content=\"I aimed my pebble, but myself\\n\\n\\nWas all the one that fell.\\n\\n\\nWas it Goliath was too large,\\n\\n\\nOr only I too small?\\n\\n\\n\\n\\n\\n\\nXXXIV.\\n\\n\\n\\n\\n\\n\\nA shady friend for torrid days\\n\\n\\nIs easier to find\\n\\n\\nThan one of higher temperature\\n\\n\\nFor frigid hour of mind.\\n\\n\\n\\n\\n\\n\\nThe vane a little to the east\\n\\n\\nScares muslin souls away;\\n\\n\\nIf broadcloth breasts are firmer\\n\\n\\nThan those of organdy,\\n\\n\\n\\n\\n\\n\\nWho is to blame? The weaver?\\n\\n\\nAh! the bewildering thread!\\n\\n\\nThe tapestries of paradise\\n\\n\\nSo notelessly are made!\\n\\n\\n\\n\\n\\n\\nXXXV.\\n\\n\\n\\n\\n\\n\\nTHE GOAL.\\n\\n\\n\\n\\n\\n\\nEach life converges to some centre\\n\\n\\nExpressed or still;\\n\\n\\nExists in every human nature\\n\\n\\nA goal,\\n\\n\\n\\n\\n\\n\\nAdmitted scarcely to itself, it may be,\\n\\n\\nToo fair\\n\\n\\nFor credibility's temerity\\n\\n\\nTo dare.\\n\\n\\n\\n\\n\\n\\nAdored with caution, as a brittle heaven,\\n\\n\\nTo reach\\n\\n\\nWere hopeless as the rainbow's raiment\\n\\n\\nTo touch,\\n\\n\\n\\n\\n\\n\\nYet persevered toward, surer for the distance;\\n\\n\\nHow high\\n\\n\\nUnto the saints' slow diligence\\n\\n\\nThe sky!\\n\\n\\n\\n\\n\\n\\nUngained, it may be, by a life's low venture,\", metadata={'source': 'data/htm/EmiTalks_4.htm', 'title': 'Emily Dickinson 4.txt · financeart/EmiTalks4 at main'})]"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Test successfully passed."
      ],
      "metadata": {
        "id": "Pr1RAGssothw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Setting Up the Langchain Tool Chain\n",
        "\n",
        "Loading the model\n"
      ],
      "metadata": {
        "id": "nnwcrrZwppj-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.chat_models import ChatOpenAI\n",
        "\n",
        "llm = ChatOpenAI(temperature=0, model=\"gpt-3.5-turbo\")"
      ],
      "metadata": {
        "id": "tfFxwnlNt-AM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d35c4f54-7e8d-4478-ed50-2ccb78277898"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Setting up the document vector store as a Retriever tool."
      ],
      "metadata": {
        "id": "cU62nF3RwKKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "doc_retriever = vectordb.as_retriever()"
      ],
      "metadata": {
        "id": "CFjGZSQY2bWo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the RetrievalQA chain and using all the documents we have in the Vector DB."
      ],
      "metadata": {
        "id": "2-3qh9ie2eCo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.chains import RetrievalQA\n",
        "\n",
        "emi_qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=doc_retriever)"
      ],
      "metadata": {
        "id": "4n5ylaE8wQIm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the retrieval is working as expected."
      ],
      "metadata": {
        "id": "6sOYSlh8wlYm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emi_qa.run(\"What is the theme of my country wardrobe?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "ZQKy7Gmrwk3n",
        "outputId": "c8029931-20ff-4c3e-de61-a3759a82652a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
            "  warn_deprecated(\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The theme of \"My Country\\'s Wardrobe\" seems to revolve around patriotism and pride in one\\'s country. The poem uses clothing and fashion metaphors to describe the nation\\'s identity and history, emphasizing the beauty and significance of its past. It also touches on the relationship between the speaker\\'s country and Great Britain, highlighting a sense of defiance and independence.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the search tool using SERP API.\n"
      ],
      "metadata": {
        "id": "yf--RcSM6MIb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install google-search-results -q"
      ],
      "metadata": {
        "id": "G_k9kCud-MSU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "131f45d6-6d56-4467-958d-c0b6000eb29d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for google-search-results (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "\n",
        "serpapi_api_key = userdata.get('serpapi_key')\n",
        "\n",
        "os.environ[\"SERPAPI_API_KEY\"] = serpapi_api_key"
      ],
      "metadata": {
        "id": "9K7yvsap-EoH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.utilities import SerpAPIWrapper\n",
        "\n",
        "search = SerpAPIWrapper()"
      ],
      "metadata": {
        "id": "XbOXzzQh-ASf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the QA and the Google search tools."
      ],
      "metadata": {
        "id": "c-2I6ElC-y1l"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import initialize_agent, Tool\n",
        "from langchain.agents import AgentType\n",
        "from langchain_community.tools import BaseTool\n",
        "from langchain_community.llms import OpenAI\n",
        "from langchain import SerpAPIWrapper\n",
        "\n",
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Emi Poetry QA System\",\n",
        "        func=emi_qa.run,\n",
        "        description=\"useful for when you need to answer questions about Emily Dickinson's poetry. Input should be a fully formed question.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Backup Emi Google Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about Emily Dickinson's poetry but only when the Emi Poetry QA System couldn't answer the query. Input should be a fully formed question.\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "rhtl7b_D9oZj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "agent = initialize_agent(tools, llm, agent=AgentType.ZERO_SHOT_REACT_DESCRIPTION, verbose=True)"
      ],
      "metadata": {
        "id": "72tp3fOe-ox6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a3d9e008-b7ca-4f76-868d-9bf2b7e483c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent.run(\"When has there been a poetry festival that included Emily Dickinson poetry in 2023?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "GZfR8q8m-p-y",
        "outputId": "b1a71863-274a-441f-a5ca-b373a28a031d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mI should start by using the Emi Poetry QA System to see if it has information on this specific poetry festival.\n",
            "Action: Emi Poetry QA System\n",
            "Action Input: Poetry festival including Emily Dickinson poetry in 2023\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mI don't have information about specific poetry festivals in 2023, including those featuring Emily Dickinson's poetry. It would be best to check with poetry organizations, event listings, or cultural institutions for updates on upcoming poetry festivals.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should now use the Backup Emi Google Search to find more information about poetry festivals in 2023 that may include Emily Dickinson's poetry.\n",
            "Action: Backup Emi Google Search\n",
            "Action Input: Poetry festivals 2023 Emily Dickinson\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mThe Tell It Slant Poetry Festival returns September 25 – October 1, 2023! The year's Festival will be hybrid with events happening online, as well as in-person at the Museum in Amherst, MA.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer.\n",
            "Final Answer: The Tell It Slant Poetry Festival in 2023 will include Emily Dickinson's poetry.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Tell It Slant Poetry Festival in 2023 will include Emily Dickinson's poetry.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding memory to application to include chat history."
      ],
      "metadata": {
        "id": "CnqYg-sH_EFR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.memory import ConversationBufferMemory, ReadOnlySharedMemory\n",
        "\n",
        "memory = ConversationBufferMemory(memory_key=\"chat_history\")\n",
        "readonlymemory = ReadOnlySharedMemory(memory=memory)"
      ],
      "metadata": {
        "id": "R9v1B7Ce_Hha"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        " We add the ability to read the memory to the chain."
      ],
      "metadata": {
        "id": "ko1K3Vsl_Pb0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "emi_qa = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=doc_retriever, memory=readonlymemory)"
      ],
      "metadata": {
        "id": "KHM5oJ3e_Xcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Re-creating the Tools list using the memory capable version of the `emi_qa` chain."
      ],
      "metadata": {
        "id": "nKTsdlKv_odP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tools = [\n",
        "    Tool(\n",
        "        name = \"Emi Poetry QA System\",\n",
        "        func=emi_qa.run,\n",
        "        description=\"useful for when you need to answer questions about Emily Dickinson's poetry. Input should be a fully formed question.\"\n",
        "    ),\n",
        "    Tool(\n",
        "        name = \"Backup Emi Google Search\",\n",
        "        func=search.run,\n",
        "        description=\"useful for when you need to answer questions about Emily Dickinson's poetry but only when the Emi Poetry QA System couldn't answer the query. Input should be a fully formed question.\"\n",
        "    ),\n",
        "]"
      ],
      "metadata": {
        "id": "_2A-iS4i_v0Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding the prompt template so the agent can respond exactly as expected."
      ],
      "metadata": {
        "id": "FjE74x-d_4LJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.agents import ZeroShotAgent, Tool, AgentExecutor\n",
        "\n",
        "prefix = \"\"\"Have a conversation with a human, answering the following questions as best you can. You have access to the following tools:\"\"\"\n",
        "suffix = \"\"\"Begin!\"\n",
        "\n",
        "{chat_history}\n",
        "Question: {input}\n",
        "{agent_scratchpad}\"\"\"\n",
        "\n",
        "prompt = ZeroShotAgent.create_prompt(\n",
        "    tools,\n",
        "    prefix=prefix,\n",
        "    suffix=suffix,\n",
        "    input_variables=[\"input\", \"chat_history\", \"agent_scratchpad\"]\n",
        ")"
      ],
      "metadata": {
        "id": "1HojDlI__-tY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Adding this prompt template to the OpenAI LLM."
      ],
      "metadata": {
        "id": "nR8F_bkxANt8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain import LLMChain, PromptTemplate\n",
        "from langchain_community.llms import OpenAI\n",
        "\n",
        "\n",
        "llm_chain = LLMChain(llm=llm, prompt=prompt)"
      ],
      "metadata": {
        "id": "y2wi-Yc6ARvB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setting up the final agent."
      ],
      "metadata": {
        "id": "pc-KsgdEA-YC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent = ZeroShotAgent(llm_chain=llm_chain, tools=tools, verbose=True)\n",
        "agent_chain = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True, memory=memory)"
      ],
      "metadata": {
        "id": "w0Qu44l4BBFI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "870860fb-a969-4b2c-b5cb-20fff5c5a220"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain.agents.mrkl.base.ZeroShotAgent` was deprecated in langchain 0.1.0 and will be removed in 0.2.0. Use create_react_agent instead.\n",
            "  warn_deprecated(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Testing the agent."
      ],
      "metadata": {
        "id": "aVPaRaqfA2sd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"When has there been a poetry festival that included Emily Dickinson poetry in 2023?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "id": "s8wcjyokA398",
        "outputId": "47db2477-8571-498c-8edf-bf06f0db3c48"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should start by using the Emi Poetry QA System to see if it has information on poetry festivals in 2023 that included Emily Dickinson's poetry.\n",
            "Action: Emi Poetry QA System\n",
            "Action Input: Poetry festivals in 2023 featuring Emily Dickinson's poetry\u001b[0m\n",
            "Observation: \u001b[36;1m\u001b[1;3mI don't have information on specific poetry festivals happening in 2023 that feature Emily Dickinson's poetry. You may want to check with poetry organizations, event listings, or cultural institutions for updates on any upcoming festivals or events dedicated to Emily Dickinson's poetry.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI should try using the Backup Emi Google Search to see if there are any upcoming poetry festivals in 2023 that include Emily Dickinson's poetry.\n",
            "Action: Backup Emi Google Search\n",
            "Action Input: Poetry festivals 2023 Emily Dickinson\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mThe Tell It Slant Poetry Festival returns September 25 – October 1, 2023! The year's Festival will be hybrid with events happening online, as well as in-person at the Museum in Amherst, MA.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The Tell It Slant Poetry Festival in 2023 will include Emily Dickinson's poetry.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Tell It Slant Poetry Festival in 2023 will include Emily Dickinson's poetry.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"Where does this festival take place?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "id": "isP5VIquBHYt",
        "outputId": "ce0ba288-6233-491f-c515-9eed2570c2da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out where the Tell It Slant Poetry Festival takes place in 2023.\n",
            "Action: Backup Emi Google Search\n",
            "Action Input: Tell It Slant Poetry Festival 2023 location\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mAmherst, MA\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The Tell It Slant Poetry Festival in 2023, which includes Emily Dickinson's poetry, takes place in Amherst, MA.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Tell It Slant Poetry Festival in 2023, which includes Emily Dickinson's poetry, takes place in Amherst, MA.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"Are there any other poets included?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 288
        },
        "id": "0lo2Id_UBQB5",
        "outputId": "8c95f789-f8c5-408d-dff9-3a1d61a50a27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I should use the Backup Emi Google Search to find out if there are any other poets included in the Tell It Slant Poetry Festival in 2023.\n",
            "Action: Backup Emi Google Search\n",
            "Action Input: \"Tell It Slant Poetry Festival 2023 poets included\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mSmith, Tiana Clark, Tess Taylor, Ada Limón, Jericho Brown, Franny Choi, Aimee Nezhukumatathil, Paisley Rekdal, Adrian Matejka, Kaveh Akbar, and Ocean Vuong.\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The Tell It Slant Poetry Festival in 2023 includes poets such as Smith, Tiana Clark, Tess Taylor, Ada Limón, Jericho Brown, Franny Choi, Aimee Nezhukumatathil, Paisley Rekdal, Adrian Matejka, Kaveh Akbar, and Ocean Vuong, in addition to Emily Dickinson's poetry.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"The Tell It Slant Poetry Festival in 2023 includes poets such as Smith, Tiana Clark, Tess Taylor, Ada Limón, Jericho Brown, Franny Choi, Aimee Nezhukumatathil, Paisley Rekdal, Adrian Matejka, Kaveh Akbar, and Ocean Vuong, in addition to Emily Dickinson's poetry.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "agent_chain.run(input=\"Is it going to happen again 2024 and if so when?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "g34SOejbucAm",
        "outputId": "e1e48b79-4b81-4da3-d24e-4558a2dfc460"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
            "\u001b[32;1m\u001b[1;3mThought: I need to find out if the Tell It Slant Poetry Festival will happen again in 2024 and when it will take place.\n",
            "Action: Backup Emi Google Search\n",
            "Action Input: \"Tell It Slant Poetry Festival 2024 dates\"\u001b[0m\n",
            "Observation: \u001b[33;1m\u001b[1;3mThe Emily Dickinson Museum is now accepting proposals for our 2024 programs: Phosphorescence Contemporary Poetry Series – a virtual event held monthly May-October AND the 12th annual Tell It Slant Poetry Festival, held September 23 – 29!\u001b[0m\n",
            "Thought:\u001b[32;1m\u001b[1;3mI now know the final answer\n",
            "Final Answer: The Tell It Slant Poetry Festival will happen again in 2024 from September 23 - 29.\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Tell It Slant Poetry Festival will happen again in 2024 from September 23 - 29.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook is adapted from the notebook developed by AI Makerspace, which was originally using Alice in Wonderland text."
      ],
      "metadata": {
        "id": "o_kqcyu82_mW"
      }
    }
  ]
}